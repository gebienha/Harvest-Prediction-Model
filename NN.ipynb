{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"combined.csv\")\n",
    "df = df[~df.index.duplicated(keep = 'first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ace16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying the datatypes of all the features\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values with the mean\n",
    "df['Number_Weeks_Used'].fillna(df['Number_Weeks_Used'].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b516ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return plots for the feature\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def normality(data,feature):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.kdeplot(data[feature])\n",
    "    plt.subplot(1,2,2)\n",
    "    stats.probplot(data[feature],plot=pylab)\n",
    "    plt.show()\n",
    "    \n",
    "#Converting Estimated Insects Count feature to Normal Distribution using Box-Cox transform\n",
    "#Plotting to check the transformation\n",
    "df['Estimated_Insects_Counts'], parameters = stats.boxcox(df['Estimated_Insects_Count'])\n",
    "normality(df,'Estimated_Insects_Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.loc[df['Number_Weeks_Used']>55,'Number_Weeks_Used'] = np.mean(df[\"Number_Weeks_Used\"])\n",
    "df.loc[df['Estimated_Insects_Count']>3500,'Estimated_Insects_Count'] = np.mean(df[\"Estimated_Insects_Count\"])\n",
    "df.loc[df['Number_Weeks_Quit']>40,'Number_Weeks_Quit'] = np.mean(df[\"Number_Weeks_Quit\"])\n",
    "df.loc[df['Number_Doses_Week']>80,'Number_Doses_Week'] = np.mean(df[\"Number_Doses_Week\"])\n",
    "df.drop(columns = [\"Estimated_Insects_Count\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predictors and Target\n",
    "y = df['Crop_Damage']\n",
    "X = df.drop(columns = ['Crop_Damage'])\n",
    "\n",
    "#Performing Train Test split using sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.65, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80663f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us normalize values for features(Number_Doses_Week,\tNumber_Weeks_Used,\tNumber_Weeks_Quit,\tEstimated_Insects_Counts)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e41359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking normalized values by creating a dataframe\n",
    "from pandas import DataFrame\n",
    "X_train_df = DataFrame(X_train)\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performed feature encoding to the X_test feature using get_dummies and then transformed\n",
    "X_test = pd.get_dummies(data = X_test, columns=[\"Season\",\"Pesticide_Use_Category\",\"Soil_Type\",\"Crop_Type\"])\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe from normalized values of test dataset\n",
    "X_test_df = DataFrame(X_test)\n",
    "X_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca34933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train_net, X_test_net, y_train_net, y_test_net = train_test_split(X, y, train_size=0.65, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11715073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do encoding for nominal data so I used get_dummies method\n",
    "X_train_net = pd.get_dummies(data = X_train_net, columns = [\"Season\",\"Pesticide_Use_Category\",\"Soil_Type\",\"Crop_Type\"])\n",
    "X_train_net.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us normalize values for features(Number_Doses_Week,\tNumber_Weeks_Used,\tNumber_Weeks_Quit,\tEstimated_Insects_Counts)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_net = scaler.fit_transform(X_train_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for Neural Nets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keras model\n",
    "\n",
    "input_dim = X_train_net.shape[1]  # Automatically use correct input size\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=input_dim, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(24, input_dim =8, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(48, activation = 'relu', kernel_initializer = 'glorot_uniform'))\n",
    "model.add(Dense(64, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(128, activation = 'relu', kernel_initializer = 'glorot_uniform'))\n",
    "model.add(Dense(96, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(64, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ba8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the keras model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c682543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the keras model on the dataset\n",
    "model.fit(X_train_net, y_train_net, epochs = 7, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2130c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd15a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make probability predictions with the model\n",
    "predictions = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ANN model to an HDF5 file\n",
    "model.save(\"Bayer_Crop_Science_Nov2021_DSInterview_ANN.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
